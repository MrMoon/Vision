# -*- coding: utf-8 -*-
"""BasicSR_inference_ESRGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JQScYICvEC3VqaabLu-lxvq9h7kSV1ML

<a href=https://github.com/xinntao/BasicSR><img src="https://raw.githubusercontent.com/xinntao/BasicSR/master/assets/basicsr.png" width="400"></a>

# ESRGAN Inference Demo
In this colab notebook, we will show how to upsample images with ESRGAN.<br>
Enjoy!

# Preparations
Before start, make sure that you choose
* Runtime Type = Python 3
* Hardware Accelerator = GPU

in the **Runtime** menu -> **Change runtime type**

## Git clone [BasicSR](https://github.com/xinntao/BasicSR) repo
"""

# Commented out IPython magic to ensure Python compatibility.
!rm -rf BasicSR
!git clone https://github.com/xinntao/BasicSR.git
# %cd BasicSR

"""## Set up the enviroment

"""

# Install pytorch
!pip install torch torchvision

# Check torch and cuda versions
import torch
print('Torch Version: ', torch.__version__)
print('CUDA Version: ', torch.version.cuda)
print('CUDNN Version: ', torch.backends.cudnn.version())
print('CUDA Available:', torch.cuda.is_available())

# Install requirements
!pip install -r requirements.txt
# Install BasicSR without cuda extentions
!python setup.py develop --no_cuda_ext

"""## Download pretrained models"""

!python scripts/download_pretrained_models.py ESRGAN

"""## Download demo test datasets"""

!python scripts/data_preparation/download_datasets.py Set5
!python scripts/data_preparation/download_datasets.py Set14

"""# Inference with ESRGAN
There are two ways to inference with ESRGAN. 
1. Test with **bascisr/test.py** and the **configuration yml** file
2. Test with **a minimum snippet of codes**, which are also put in **inference/inference_esrgan.py**

## Inference method 1: Test with configuration file

1. First, you need to modify the configuration yml file **options/test/ESRGAN/test_ESRGAN_x4_woGT.yml**, especially the dataset path and pretrained model path
```yaml
name: ESRGAN_SRx4_DF2KOST_official
model_type: ESRGANModel
scale: 4
num_gpu: 1  # set num_gpu: 0 for cpu mode
manual_seed: 0
# datasets
datasets:
  test_1:  # the 1st test dataset
    name: Set5
    type: SingleImageDataset
    dataroot_lq: datasets/Set5/LRbicx4
    io_backend:
      type: disk
  test_2:  # the 2st test dataset
    name: Set14
    type: SingleImageDataset
    dataroot_lq: datasets/Set14/LRbicx4
    io_backend:
      type: disk
# network structures
network_g:
  type: RRDBNet
  num_in_ch: 3
  num_out_ch: 3
  num_feat: 64
  num_block: 23
  num_grow_ch: 32
# path
path:
  pretrain_network_g: experiments/pretrained_models/ESRGAN/ESRGAN_SRx4_DF2KOST_official-ff704c30.pth
  strict_load_g: true
# validation settings
val:
  save_img: true
  suffix: ~  # add suffix to saved images, if None, use exp name
```

2. Run the following command
3. The restoration results are in the **results** folder
"""

!python basicsr/test.py -opt options/test/ESRGAN/test_ESRGAN_x4_woGT.yml

"""## Inference method 2: A minimum snippet of testing codes

Make modification accordingly and the restoration results are in the **results/ESRGAN** folder.
"""

import cv2
import glob
import numpy as np
import os
import torch

from basicsr.models.archs.rrdbnet_arch import RRDBNet

# configuration
model_path = 'experiments/pretrained_models/ESRGAN/ESRGAN_SRx4_DF2KOST_official-ff704c30.pth'
folder = 'datasets/Set14/LRbicx4'
device = 'cuda'

device = torch.device(device)

# set up model
model = RRDBNet(
    num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32)
model.load_state_dict(torch.load(model_path)['params'], strict=True)
model.eval()
model = model.to(device)

os.makedirs('results/ESRGAN', exist_ok=True)
for idx, path in enumerate(sorted(glob.glob(os.path.join(folder, '*')))):
    imgname = os.path.splitext(os.path.basename(path))[0]
    print(idx, imgname)
    # read image
    img = cv2.imread(path, cv2.IMREAD_COLOR).astype(np.float32) / 255.
    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]],
                                        (2, 0, 1))).float()
    img = img.unsqueeze(0).to(device)
    # inference
    with torch.no_grad():
        output = model(img)
    # save image
    output = output.data.squeeze().float().cpu().clamp_(0, 1).numpy()
    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))
    output = (output * 255.0).round().astype(np.uint8)
    cv2.imwrite(f'results/ESRGAN/{imgname}_ESRGAN.png', output)

"""The above code snippet is also put in **inference/inference_esrgan.py**.<br>
You can run this code snippet from the command line:
"""

!python inference/inference_esrgan.py --model_path experiments/pretrained_models/ESRGAN/ESRGAN_SRx4_DF2KOST_official-ff704c30.pth --folder datasets/Set14/LRbicx4

"""# Show results

We show and compare the input image, ESRGAN results and the Ground-truth (GT) image.
"""

import cv2
import matplotlib.pyplot as plt

def imread(img_path):
  img = cv2.imread(img_path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  return img

# read images
img_input = imread('datasets/Set14/LRbicx4/baboon.png')
img_esrgan = imread('results/ESRGAN/baboon_ESRGAN.png')
img_gt = imread('datasets/Set14/GTmod12/baboon.png')

# show and compare the results
fig = plt.figure(figsize=(25, 10))
ax1 = fig.add_subplot(1, 3, 1) 
plt.title('Input image', fontsize=16)
ax1.axis('off')
ax2 = fig.add_subplot(1, 3, 2)
plt.title('ESRGAN output', fontsize=16)
ax2.axis('off')
ax3 = fig.add_subplot(1, 3, 3) 
plt.title('Ground-truth image', fontsize=16)
ax3.axis('off')
ax1.imshow(img_input)
ax2.imshow(img_esrgan)
ax3.imshow(img_gt)

"""# Limitations
ESRGAN is mainly developped for research purpose and there are several limitations for practical usage. 
1. Scale. It now only supports for X4 upsampling. 
2. Kernel mismatch. The provided ESRGAN model is trained with MATLAB bicubic downsampling kernel (you can treat it as a blur type). If the blur type of the real image is different from the bicubic downsampling kernel, which is the usual case, the results are not satisfactory. You may need to fine-tune the pretrained ESRGAN model to improve the output quality.
3. Other degradations like JPEG compressions and noise. The pretrained ESRGAN model is for super-resolution, and does not take the JPEG compressions and noise into considerations. So it cannot handle these degradations. You may first remove theses degradations or fine-tune it to give this model such ability.

# Try it on uploaded images

## 1. Upload images
"""

import os
from google.colab import files
import shutil

upload_folder = 'datasets/upload'
result_folder = 'results/ESRGAN'

if os.path.isdir(upload_folder):
    shutil.rmtree(upload_folder)
if os.path.isdir(result_folder):
    shutil.rmtree(result_folder)
os.mkdir(upload_folder)
os.mkdir(result_folder)

# upload images
uploaded = files.upload()
for filename in uploaded.keys():
  dst_path = os.path.join(upload_folder, filename)
  print(f'move {filename} to {dst_path}')
  shutil.move(filename, dst_path)

"""## 2. Inference"""

# inference
!python inference/inference_esrgan.py --model_path experiments/pretrained_models/ESRGAN/ESRGAN_SRx4_DF2KOST_official-ff704c30.pth --folder datasets/upload

"""## 3. Visualize (Optional)"""

# visualize
import os
import glob
def display(img1, img2):
  fig = plt.figure(figsize=(25, 10))
  ax1 = fig.add_subplot(1, 2, 1) 
  plt.title('Input image', fontsize=16)
  ax1.axis('off')
  ax2 = fig.add_subplot(1, 2, 2)
  plt.title('ESRGAN output', fontsize=16)
  ax2.axis('off')
  ax1.imshow(img1)
  ax2.imshow(img2)
  
input_list = sorted(glob.glob(os.path.join(upload_folder, '*')))
output_list = sorted(glob.glob(os.path.join(result_folder, '*')))
for input_path, output_path in zip(input_list, output_list):
  img_input = imread(input_path)
  img_output = imread(output_path)
  display(img_input, img_output)

"""## 4. Download results"""

# download the result
print(f'Download {result_folder}')
os.system(f'zip -r -j download.zip {result_folder}/*')
files.download("download.zip")